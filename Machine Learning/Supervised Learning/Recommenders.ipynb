{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72aab5c-a99c-4240-a29f-0861ee6609e2",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "## Recommenders\n",
    "\n",
    "Author: Bingchen Wang\n",
    "\n",
    "Last Updated: 10 Sep, 2022\n",
    "\n",
    "---\n",
    "<nav>\n",
    "    <a href=\"../Machine%20Learning.ipynb\">Machine Learning</a> |\n",
    "    <a href=\"./Supervised Learning.ipynb\">Supervised Learning</a>\n",
    "</nav>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9f6b1-4568-412b-bdf3-75a7dec6046e",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Concepts:\n",
    "- [Recommendation Systems](#RS)\n",
    "- [Collaborative Filtering](#CF)\n",
    "- [Content-based Filtering](#CBF)\n",
    "- [Finding Similar Items/Users](#FSIU)\n",
    "\n",
    "Implementation:\n",
    "- [TensorFlow](./Recommenders/Tensorflow%20Implementation.ipynb)\n",
    "- PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360f990-9cae-4776-be55-8bc4cd2d190a",
   "metadata": {},
   "source": [
    "<a name = \"RS\"></a>\n",
    "### Recommondation Systems\n",
    "<blockquote>\n",
    "    A recommender system, or a recommendation system (sometimes replacing 'system' with a synonym such as platform or engine), is a subclass of information filtering system that provide suggestions for items that are most pertinent to a particular user.\n",
    "    -- Wikipedia\n",
    "</blockquote>\n",
    "\n",
    "<a name = \"CF\"></a>\n",
    "### Collaborative Filtering\n",
    "\n",
    "#### Notation\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:left\">Concept</th>\n",
    "        <th style=\"text-align:left\">Notation</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>number of items</td>\n",
    "        <td>$n_m$</td>\n",
    "    </tr>    \n",
    "    <tr>\n",
    "        <td>number of users</td>\n",
    "        <td>$n_u$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>number of features for each item</td>\n",
    "        <td>$n$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>item $i$ is rated by user $j$</td>\n",
    "        <td>$r(i,j) = 1$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>rating of item $i$ given by user $j$</td>\n",
    "        <td>$y(i,j)$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>feature rating of item $i$</td>\n",
    "        <td>$\\mathbf{x}^{(i)}$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>preference of user $j$</td>\n",
    "        <td>$\\mathbf{w}^{(j)}, b^{(j)}$</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "#### Algorithm\n",
    "Target: ratings by users, click by users, likes by users etc. <br>\n",
    "Prediction is given by:\n",
    "$$\n",
    "\\hat y(i,j) = \\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}\n",
    "$$\n",
    "The cost function is given by:\n",
    "$$\n",
    "J(\\mathbf{W}, \\mathbf{b}, \\mathbf{X})= \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2\n",
    "+\\underbrace{\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2}_{\\text{regularisation}}\n",
    "$$\n",
    "Trainable parameters: $\\mathbf{W}, \\mathbf{b}, \\mathbf{X}$.\n",
    "\n",
    "#### Mean Normalisation\n",
    "Intuition:\n",
    "- For a new user who has not rated any item, the regularization term drives the individual parameters to 0 (assuming $b^{(j)}$ is initialised as 0 and without normalisation).\n",
    "\n",
    "Procedure:\n",
    "- Compute average ratings across the columns (where ratings are available), $\\mu_i$\n",
    "- Subtract the ratings by the average ratings (where ratings are available) $\\tilde y(i,j) = y(i,j) - \\mu_i$\n",
    "- Train models using $\\mathbf{X}$ and $\\mathbf{\\tilde y}$\n",
    "- For predictions, use $\\hat y(i,j) = \\hat{\\tilde{y}}(i,j) + \\mu_i$\n",
    "\n",
    "$0/0$ problem:\n",
    "- Can be solved by adding a small number to the denominator.\n",
    "\n",
    "Benefits:\n",
    "- Better predictions for users who have not rated any item or have only rated a few items.\n",
    "- Make the optimisation algorithm run a little faster.\n",
    "\n",
    "<a name = \"CBF\"></a>\n",
    "### Content-based Filtering\n",
    "\n",
    "#### Notation\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:left\">Concept</th>\n",
    "        <th style=\"text-align:left\">Notation</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>item content vector</td>\n",
    "        <td>$\\mathbf{x}_m^{(i)}$</td>\n",
    "    </tr>    \n",
    "    <tr>\n",
    "        <td>user content vector</td>\n",
    "        <td>$\\mathbf{x}_u^{(j)}$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>item/user feature dimension</td>\n",
    "        <td>$n$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>item feature vector (post NN)</td>\n",
    "        <td>$\\mathbf{v}_m^{(i)} \\in \\mathbb{R}^n$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>user feature vector (post NN)</td>\n",
    "        <td>$\\mathbf{v}_u^{(j)} \\in \\mathbb{R}^n$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>rating of item $i$ given by user $j$</td>\n",
    "        <td>$y(i,j)$</td>\n",
    "    </tr>\n",
    "</table>\n",
    "<div class = \"alert alert-block alert-info\"><b>Note:</b> Item features can also be engineered using the target, e.g. average user ratings per item. </div>\n",
    "\n",
    "#### Algorithm\n",
    "<figure>\n",
    "    <center> <img src=\"./Recommenders/content-based filtering.pdf\"   style=\"width:100%\" ></center>\n",
    "</figure>\n",
    "\n",
    "Target: ratings by users, click by users, likes by users etc. <br>\n",
    "Prediction is given by:\n",
    "$$\n",
    "\\hat y(i,j) = \\mathbf{v}_u^{(j)} \\cdot \\mathbf{v}_m^{(i)}\n",
    "$$\n",
    "The cost function is given by:\n",
    "$$\n",
    "J(\\mathbf{W}, \\mathbf{b})= \\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{v}_u^{(j)} \\cdot \\mathbf{v}_m^{(i)} - y^{(i,j)})^2\n",
    "+\\text{regularisation of neural networks weights}\n",
    "$$\n",
    "Trainable parameters: $\\mathbf{W}, \\mathbf{b}$ (neural network parameters).\n",
    "\n",
    "#### Preprocessing\n",
    "##### Input user content and item content vectors\n",
    "- Apply the **standard scaler** along each feature (for neural network inputs)\n",
    "$$\n",
    "z = \\frac{(x- \\mu)}{s}\n",
    "$$\n",
    "##### Target ratings\n",
    "- Apply the **min-max scaler** to scale $y$ to be between $-1$ and $1$.\n",
    "$$\n",
    "z = \\frac{y - min}{max -min} \\cdot (1) + (1- \\frac{y- min}{max - min}) \\cdot (-1)\n",
    "$$\n",
    "\n",
    "<a name = \"FSIU\"></a>\n",
    "### Finding Similar Items/Users\n",
    "Similar users have similar user feature vectors, while similar items have similar item feature vectors.\n",
    "\n",
    "Measure similarity by the squared distance between the two vectors:\n",
    "- User\n",
    "$$\n",
    "\\left \\Vert v_u^{(j)} - v_u^{(k)} \\right \\Vert^2 = \\sum_{l=1}^{n}(v_{u_l}^{(j)} - v_{u_l}^{(k)})^2\n",
    "$$\n",
    "- Item\n",
    "$$\n",
    "\\left \\Vert x_m^{(i)} - x_m^{(h)} \\right \\Vert^2 = \\sum_{l=1}^{n}(x_{m_l}^{(i)} - x_{m_l}^{(h)})^2 \\;\\;\\;\\text{(collaborate filtering)}\n",
    "$$\n",
    "$$\n",
    "\\left \\Vert v_m^{(i)} - v_m^{(h)} \\right \\Vert^2 = \\sum_{l=1}^{n}(v_{m_l}^{(i)} - v_{m_l}^{(h)})^2 \\;\\;\\;\\text{(content-based filtering)}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datascience)",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
