{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a7a0e3-6db0-4026-95dd-31a23666364a",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "## Optimization\n",
    "\n",
    "Author: Bingchen Wang\n",
    "\n",
    "Last Updated: 13 Nov, 2022\n",
    "\n",
    "\n",
    "<nav>\n",
    "    <b>Deep learning navigation:</b> <a href=\"./Deep Learning Basics.ipynb\">Basics</a>\n",
    "</nav>\n",
    "\n",
    "---\n",
    "<nav>\n",
    "    <a href=\"../Machine%20Learning.ipynb\">Machine Learning</a> |\n",
    "    <a href=\"../Supervised Learning/Supervised%20Learning.ipynb\">Supervised Learning</a>\n",
    "</nav>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118eba6b-de21-4c22-8f67-7a85f42fba8f",
   "metadata": {},
   "source": [
    "## Contents\n",
    "Algorithms:\n",
    "- [Batch Gradient Descent](#BGD)\n",
    "- [Stochastic Gradient Descent](#SGD)\n",
    "- [Mini-batch Gradient Descent](#MBGD)\n",
    "- [Gradient Descent with Momentum](#GDwM)\n",
    "- [RMSprop](#RMSp)\n",
    "- [Adam](#ADAM)\n",
    "\n",
    "Technique:\n",
    "- [Learning Rate Decay](#LRD)\n",
    "- [Batch Normalization](#BN)\n",
    "    - [PyTorch Implementation](./PyTorch/Batch%20Norm.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b62635-4d04-42c7-8708-f24cbe2f5bc0",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "Consider the linear model/hypothesis\n",
    "$$\n",
    "h_{\\theta}(x^{(i)}) = \\theta^{\\mathsf{T}} x^{(i)}\n",
    "$$\n",
    "and the squared loss function\n",
    "$$\n",
    "L(\\theta) = \\frac{1}{2} {\\left(y^{(i)} - h_{\\theta}(x^{(i)})\\right)}^2\n",
    "$$\n",
    "\n",
    "<a name = \"BGD\"></a>\n",
    "### Batch Gradient Descent\n",
    "Use the entire training set of $m$ examples in every iteration of the training process.\n",
    "<blockquote>\n",
    "    Start with some $\\theta \\in \\mathbb{R}^p$ <br>\n",
    "    Repeat until convergence:\n",
    "    <blockquote>\n",
    "        Compute $h_\\theta(x^{(i)})$ for <b>all</b> examples $i = 1, \\dots, m$. <br>\n",
    "        Calculate the cost $$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m {\\left(y^{(i)} - h_{\\theta}(x^{(i)})\\right)}^2.$$ <br>\n",
    "        Update the parameters $$\\theta_j := \\theta_j - \\alpha \\frac{\\partial J}{\\partial \\theta_j}, \\;\\;\\; \\text{for } j = 1, \\dots, P$$\n",
    "    </blockquote>\n",
    "</blockquote>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a91a440-97f6-4b38-9f4f-81fe227adf57",
   "metadata": {},
   "source": [
    "<a name =\"SGD\"></a>\n",
    "### Stochastic Gradient Descent\n",
    "Use a single example in every iteration of the training process.\n",
    "\n",
    "<blockquote>\n",
    "    Start with some $\\theta \\in \\mathbb{R}^p$ <br>\n",
    "    Repeat until an approximate minimum is obtained or a certain threshold is met (e.g., max numbers of epochs):\n",
    "    <blockquote>\n",
    "        Randomly shuffle examples in the training set. <br>\n",
    "        For $i = 1, \\dots, m$ do:\n",
    "        <blockquote>\n",
    "            Compute $h_\\theta(x^{(i)})$. <br>\n",
    "            Calculate the cost $$J(\\theta) = \\frac{1}{2} {\\left(y^{(i)} - h_{\\theta}(x^{(i)})\\right)}^2.$$ <br>\n",
    "            Update the parameters $$\\theta_j := \\theta_j - \\alpha \\frac{\\partial J}{\\partial \\theta_j}, \\;\\;\\; \\text{for } j = 1, \\dots, P$$\n",
    "        <blockquote>\n",
    "    </blockquote>\n",
    "</blockquote>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c439007-958f-4c28-a9b3-ffa6226f0bf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name = \"MBGD\"></a>\n",
    "### Mini-batch Gradient Descent\n",
    "Use a subset (a mini-batch) of the training set in every iteration of the training process. Denote the size of a mini-batch as $m_t$ and the total number of mini-batches as $T$, such that:\n",
    "$$\n",
    "m = m_t T\n",
    "$$\n",
    "<div class = \"alert alert-block alert-info\"> Typical choices for $m_t$: 64, 128, 256, 512, 1024. (Make sure that the mini-batch fits in the CPU/GPU memory.)\n",
    "</div>\n",
    "Further, denote the data in the mini-batch $t = 1, \\dots, T$ as $\\{X^{\\{t\\}}, y^{\\{t\\}}\\}$.\n",
    "\n",
    "<blockquote>\n",
    "    Start with some $\\theta \\in \\mathbb{R}^p$ <br>\n",
    "    Repeat until an approximate minimum is obtained or a certain threshold is met (e.g., max numbers of epochs):\n",
    "    <blockquote>\n",
    "        Randomly shuffle examples in the training set. Split the training set into $T$ mini-batches.<br>\n",
    "        For $t = 1, \\dots, T$ do:\n",
    "        <blockquote>\n",
    "            Compute $h_\\theta(x^{\\{t\\}(i)})$ for all examples in the mini-batch $t$. <br>\n",
    "            Calculate the cost $$J(\\theta) = \\frac{1}{2m_t} \\sum_{i = 1}^{m_t}{\\left(y^{\\{t\\}(i)} - h_{\\theta}(x^{\\{t\\}(i)})\\right)}^2.$$ <br>\n",
    "            Update the parameters $$\\theta_j := \\theta_j - \\alpha \\frac{\\partial J}{\\partial \\theta_j}, \\;\\;\\; \\text{for } j = 1, \\dots, P$$\n",
    "        </blockquote>\n",
    "    </blockquote>\n",
    "</blockquote>\n",
    "<div class = \"alert alert-block alert-success\"><b>Advantages of mini-batch gradient descent</b>:\n",
    "<ul>\n",
    "    <li> Make use of vectorization to speed up the training.\n",
    "    <li> Make progress without processing the entire training set.\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "#### Performance Comparisions: Batch, Stochastic & Mini-batch Gradient Descents\n",
    "<div style = \"text-align: center;\">\n",
    "    <img src=\"./images/gradient descent first 100 epochs.png\" style=\"width:60%;\" >\n",
    "    <img src=\"./images/gradient descent last 10 epochs.png\" style=\"width:60%;\" >\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405642c-7449-423f-b053-d931d1adf66f",
   "metadata": {},
   "source": [
    "<a name = \"GDwM\"></a>\n",
    "### Gradient Descent with Momentum\n",
    "\n",
    "#### Expoentially Weighted Moving Averages\n",
    "Denote the original time series examples as $\\{x_t\\}_{t=1}^T$.\n",
    "\n",
    "The **exponentially weighted moving averages** are computed using the recursive formula:\n",
    "$$\n",
    "\\begin{align}\n",
    "v_0 = & 0 \\\\\n",
    "v_t = & \\beta v_{t-1} + (1-\\beta) x_t, \\text{ for } t=1, \\dots, T\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\beta$ is a hyper-parameter that governs the smoothness of the averages. Roughly speaking, $v_t$ can be interpreted as approximately averaging over $\\frac{1}{1-\\beta}$ days (related to the fact that $(1-\\frac{1}{n})^n \\approx \\frac{1}{e}$, which is considered small enough in contribution to the average).\n",
    "<div class = \"alert alert-block alert-info\"> <b>Advantage over simple moving averages/windows:</b> Saves on memory (just need to keep one running variable and keep overwriting it), and computation.<br>\n",
    "<b>Disadvantage vis-Ã -vis simple moving averages/windows:</b> not the most accurate way to compute an average.\n",
    "</div>\n",
    "\n",
    "A problem with expoentially weighted moving averages is that it requires a **burn-in period** to be able to give sensible estimates of averages, which is conspicuous from the follow equations:\n",
    "$$\n",
    "\\begin{align}\n",
    "v_1 = & (1-\\beta) x_1 \\\\\n",
    "v_2 = & (1-\\beta)\\beta x_1 + (1-\\beta) x_2 \\\\\n",
    "v_3 = & (1-\\beta)\\beta^2 x_1 + (1-\\beta)\\beta x_2 + (1-\\beta) x_3 \\\\\n",
    "\\cdots &\n",
    "\\end{align}\n",
    "$$\n",
    "The closer $\\beta$ is to 1, the longer the burn-in period needs to be. To solve this problem and ensure better estimates near the beginning of the time series, bias correction can be used to improve the algorithm:\n",
    "$$\n",
    "\\tilde v_t = \\frac{v_t}{1-\\beta^t}, \\text{ for } t=1, \\dots, T\n",
    "$$\n",
    "<div class = \"alert alert-block alert-danger\"> <b>Note:</b> To apply bias correction, compute the un-corrected series first and then multiply the values of the original uncorrected series by the bias correction terms respectively.\n",
    "</div>\n",
    "<div class = \"alert alert-block alert-success\"> This makes use of the following result in algebra:\n",
    "    $$\n",
    "    s_t = \\sum_{s = 1}^t (1-\\beta) \\beta^{s-1} = (1-\\beta) \\frac{1 - \\beta^t}{1-\\beta} = 1 - \\beta^t\n",
    "    $$\n",
    "so\n",
    "    $$\n",
    "    \\tilde s_t = \\frac{s_t}{1-\\beta^t} = 1\n",
    "    $$\n",
    "</div>\n",
    "\n",
    "<div style = \"text-align: center;\">\n",
    "    <img src=\"./images/exponentially weighted moving averages.png\" style=\"width:80%;\" > <br>\n",
    "    Applying exponentially weighted moving averages to the Oxford daily temperature data. \n",
    "</div>\n",
    "\n",
    "#### Gradient Descent with Momentum\n",
    "<blockquote>\n",
    "    Initiate $v_{d\\theta_j} = 0, \\text{ for } j = 1, \\dots, P$. <br>\n",
    "    On iteration $t$ (e.g., with mini-batch gradient descent):\n",
    "    <blockquote>\n",
    "        Compute $d \\theta_j := \\frac{\\partial J}{\\partial \\theta_j}, \\text{ for } j = 1, \\dots, P$ on the current mini-batch. <br>\n",
    "        Update the momentum terms:\n",
    "        $$\n",
    "        v_{d\\theta_j} := \\beta v_{d\\theta_j} + (1-\\beta) d \\theta_j, \\text{ for } j = 1, \\dots, P\n",
    "        $$\n",
    "        Update the parameter:\n",
    "        $$\n",
    "        \\theta_j := \\theta_j - \\alpha v_{d\\theta_j}, \\text{ for } j = 1, \\dots, P\n",
    "        $$\n",
    "    </blockquote>\n",
    "</blockquote>\n",
    "\n",
    "**Hyperparameters:** $\\alpha, \\beta$ ($= 0.9$ usually works well; i.e., averaging over the last 10 gradients).\n",
    "<div class = \"alert alert-block alert-info\"> <b>Note:</b> Sometimes, the following equivalent updating rule is used:\n",
    "    $$\n",
    "    v_{d\\theta_j} := \\beta v_{d\\theta_j} + d \\theta_j, \\text{ for } j = 1, \\dots, P\n",
    "    $$\n",
    "where $\\alpha$ needs to be re-tuned with a factor of $(1-\\beta)$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81848d2-b7d8-4c33-bebf-e33456ee1725",
   "metadata": {},
   "source": [
    "### RMSprop\n",
    "<blockquote>\n",
    "    Initiate $s_{d\\theta_j} = 0, \\text{ for } j = 1, \\dots, P$ and $\\epsilon = 10^{-8}$. <br>\n",
    "    On iteration $t$ (e.g., with mini-batch gradient descent):\n",
    "    <blockquote>\n",
    "        Compute $d \\theta_j := \\frac{\\partial J}{\\partial \\theta_j}, \\text{ for } j = 1, \\dots, P$ on the current mini-batch. <br>\n",
    "        Update the mean squared term:\n",
    "        $$\n",
    "        s_{d\\theta_j} := \\beta_2 s_{d\\theta_j} + (1-\\beta_2) d \\theta_j^2, \\text{ for } j = 1, \\dots, P\n",
    "        $$\n",
    "        Update the parameter:\n",
    "        $$\n",
    "        \\theta_j := \\theta_j - \\alpha \\frac{d\\theta_j}{\\sqrt{s_{d\\theta_j} + \\epsilon}}, \\text{ for } j = 1, \\dots, P\n",
    "        $$\n",
    "    </blockquote>\n",
    "</blockquote>\n",
    "\n",
    "<div class = \"alert alert-block alert-success\"> <b>Note:</b> We add $\\epsilon$ to the denominator to avoid the divide-by-zero problem.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276285c1-7173-40c0-b91c-22d4f9af1c8b",
   "metadata": {},
   "source": [
    "<a name = \"ADAM\"></a>\n",
    "### Adaptive Moment Estimation (Adam)\n",
    "<blockquote>\n",
    "    Initiate $v_{d\\theta_j} = 0, s_{d\\theta_j} = 0, \\text{ for } j = 1, \\dots, P$ and $\\epsilon = 10^{-8}$. <br>\n",
    "    On iteration $t$ (e.g., with mini-batch gradient descent):\n",
    "    <blockquote>\n",
    "        Compute $d \\theta_j := \\frac{\\partial J}{\\partial \\theta_j}, \\text{ for } j = 1, \\dots, P$ on the current mini-batch. <br>\n",
    "        Update the momentum and the mean squared term:\n",
    "        $$\n",
    "        \\begin{align}\n",
    "        v_{d\\theta_j} := & \\beta_1 v_{d\\theta_j} + (1-\\beta_1) d \\theta_j \\\\\n",
    "        s_{d\\theta_j} := & \\beta_2 s_{d\\theta_j} + (1-\\beta_2) d \\theta_j^2\n",
    "        \\end{align}\n",
    "        $$\n",
    "        for $j = 1, \\dots, P$. <br><br>\n",
    "        Apply bias corrections:\n",
    "        $$\n",
    "        \\begin{align}\n",
    "        v_{d\\theta_j}^{\\text{corrected}} = & \\frac{v_{d\\theta_j}}{1-\\beta_1^t} \\\\\n",
    "        s_{d\\theta_j}^{\\text{corrected}} = & \\frac{s_{d\\theta_j}}{1-\\beta_2^t}\n",
    "        \\end{align}\n",
    "        $$\n",
    "        for $j = 1, \\dots, P$. <br><br>\n",
    "        Update the parameter:\n",
    "        $$\n",
    "        \\theta_j := \\theta_j - \\alpha \\frac{v_{d\\theta_j}^{\\text{corrected}}}{\\sqrt{s_{d\\theta_j}^{\\text{corrected}} + \\epsilon}}, \\text{ for } j = 1, \\dots, P\n",
    "        $$\n",
    "    </blockquote>\n",
    "</blockquote>\n",
    "\n",
    "**Typical values for the hyperparameters:**\n",
    "- $\\alpha$: needs to be tuned\n",
    "- $\\beta_1$ (momentum update): 0.9\n",
    "- $\\beta_2$ (mean squared update): 0.999\n",
    "- $\\epsilon$ : $10^{-8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2436dfb-a870-4d1e-95a8-6a2bb98cb8f7",
   "metadata": {},
   "source": [
    "## Technique\n",
    "<a name = \"LRD\"></a>\n",
    "### Learning Rate Decay\n",
    "Denote the current epoch as $i$, the decay rate as $k$ and the current mini-batch as $t$.\n",
    "\n",
    "#### Time-based decay\n",
    "$$\n",
    "\\alpha = \\frac{1}{1 + k \\times (i-1)} \\alpha_0\n",
    "$$\n",
    "#### Exponential decay\n",
    "$$\n",
    "\\alpha = k^{i-1}\\alpha_0\n",
    "$$\n",
    "#### Inverse square root decay\n",
    "**Version 1**: Based on the epoch number,\n",
    "$$\n",
    "\\alpha = \\frac{k}{\\sqrt{i}} \\alpha_0\n",
    "$$\n",
    "**Version 2**: Based on the mini-batch number,\n",
    "$$\n",
    "\\alpha = \\frac{k}{\\sqrt{t}} \\alpha_0\n",
    "$$\n",
    "#### Discrete staircase decay\n",
    "Denote the length of a step as $L_\\text{step}$.\n",
    "$$\n",
    "\\alpha = k^{\\left\\lfloor \\frac{i-1}{L_\\text{step}} \\right\\rfloor}\\alpha_0\n",
    "$$\n",
    "\n",
    "#### Comparisons of different decay methods\n",
    "<div style = \"text-align: center;\">\n",
    "    <img src=\"./images/Learning rate decay.png\" style=\"width:60%;\" > <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d417f-38d3-4cf4-ae26-06967d9ce745",
   "metadata": {},
   "source": [
    "<a name = \"BN\"></a>\n",
    "### Batch Normalization\n",
    "**Recall:** Normalization input features can speed up learning. <br>\n",
    "**Motivation:** Can we normalize input to each layer so as to make the training of the parameters in each layer faster? <br>\n",
    "**Effects of batch normalization:**\n",
    "- Speed up learning\n",
    "- Make the hyperparameter search problem much easier, with a much bigger range of hyperparameters that work well.\n",
    "- Have slight regularization effects\n",
    "\n",
    "#### Batch Normalization\n",
    "<blockquote>\n",
    "Given some intermediate values in a neural network $z^{[l](1)}, \\dots, z^{[l](m)}$, compute\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu = & \\frac{1}{m} \\sum_i z^{[l](i)} \\\\\n",
    "\\sigma^2 = & \\frac{1}{m} \\sum_i {(z^{[l](i)} - \\mu)}^2 \\\\\n",
    "z^{[l](i)}_{\\text{norm}} = & \\frac{z^{[l](i)} - \\mu}{\\sqrt{\\sigma^2 +\\epsilon}} \\\\\n",
    "\\tilde z^{[l](i)} = & \\gamma z^{[l](i)}_{\\text{norm}} + \\beta\n",
    "\\end{align}\n",
    "$$\n",
    "Then compute $a^{[l]}$ using $\\tilde z^{[l]}$ instead of $z^{[l]}$.\n",
    "</blockquote>\n",
    "\n",
    "Batch Normalization introduces **two new learnable parameters** to each layer of the model: $\\gamma$ and $\\beta$, which govern the **variance** and the **mean** of the hidden linear units of the layer.\n",
    "\n",
    "<div class = \"alert alert-block alert-info\"> <b>Note:</b> if $\\gamma = \\sqrt{\\sigma^2 +\\epsilon} $ and $\\beta = \\mu$, then\n",
    "    $$\n",
    "    \\tilde z^{[l](i)} = z^{[l](i)}.\n",
    "    $$\n",
    "So by choosing appropriate values of $\\gamma$ and $\\sigma^2$, this process is essentially computing an identity function. But setting $\\gamma$ and $\\sigma^2$ to be trainable allows for other means and variances.\n",
    "</div>\n",
    "\n",
    "<div class = \"alert alert-block alert-info\"> <b>Why do we need an extra step, i.e., $\\tilde z^{[l](i)} = \\gamma z^{[l](i)}_{\\text{norm}} + \\beta$?</b> <br>\n",
    "    This allows us to better take advantage of the non-linearity of some activation functions, e.g. sigmoid, instead of having most of the values concentrated on a small region of the (approximately) linear regime.\n",
    "</div>\n",
    "\n",
    "What batch norm does essentially is to **standardize** the hidden linear units of a layer to have a **fixed mean** and a fixed **variance**, governed by the parameters $\\beta$ and $\\gamma$.\n",
    "\n",
    "<div style = \"text-align: center;\">\n",
    "    <img src=\"./images/Batch normalization in a NN.jpg\" style=\"width:100%;\" > <br>\n",
    "</div>\n",
    "\n",
    "#### Backprop for Batch Norm\n",
    "**How does batch norm affect the flow of backpropagation?** \n",
    "\n",
    "As is evident from the previous section, batch norm introduces an additional step in the forward propagation from $z^{[l]}$ to $\\tilde z^{[l]}$. Thus, during the backprop stage, the key is to figure out **the flow from $d \\tilde z^{[l]}$ to $d z^{[l]}$**. A computation graph can be used to solve the puzzle. Yet, here we adopt a *calculus approach*.\n",
    "\n",
    "To simply notation, we drop the layer labels, and focus on the following process:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z \\rightarrow Z_{\\text{norm}} \\rightarrow \\tilde Z \\\\\n",
    "\\left[\\begin{array}{cccc}\n",
    "z^{(1)}_1 & z^{(2)}_1 & \\cdots & z^{(m)}_1 \\\\\n",
    "z^{(1)}_2 & z^{(2)}_2 & \\cdots & z^{(m)}_2 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "z^{(1)}_n & z^{(2)}_n & \\cdots & z^{(m)}_n\n",
    "\\end{array}\\right] \\rightarrow\n",
    "\\left[\\begin{array}{cccc}\n",
    "z^{(1)}_{1,\\text{norm}} & z^{(2)}_{1,\\text{norm}} & \\cdots & z^{(m)}_{1,\\text{norm}} \\\\\n",
    "z^{(1)}_{2,\\text{norm}} & z^{(2)}_{2,\\text{norm}} & \\cdots & z^{(m)}_{2,\\text{norm}} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "z^{(1)}_{n,\\text{norm}} & z^{(2)}_{n,\\text{norm}} & \\cdots & z^{(m)}_{n,\\text{norm}}\n",
    "\\end{array}\\right] \\rightarrow\n",
    "\\left[\\begin{array}{cccc}\n",
    "\\tilde z^{(1)}_1 & \\tilde z^{(2)}_1 & \\cdots & \\tilde z^{(m)}_1 \\\\\n",
    "\\tilde z^{(1)}_2 & \\tilde z^{(2)}_2 & \\cdots & \\tilde z^{(m)}_2 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\tilde z^{(1)}_n & \\tilde z^{(2)}_n & \\cdots & \\tilde z^{(m)}_n\n",
    "\\end{array}\\right] \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where each matrix has dimension $(n, m)$â$n$ is the number of features and $m$ the number of examples. Our strategy is to focus on **element-wise gradients**, i.e., $\\frac{\\partial J}{\\partial z^{(j)}_{k}}$, and use the **Chain Rule**.\n",
    "\n",
    "Recall that\n",
    "$$\n",
    "\\begin{equation}\n",
    "z^{(i)}_{k, \\text{norm}} = \\frac{z^{(i)}_k - \\mu_k}{\\sqrt{\\sigma^2_k + \\epsilon}}, \\;\\;\\; \\tilde z^{(i)}_k = \\gamma_k z^{(i)}_{k, \\text{norm}} + \\beta_k,\\;\\;\\;\n",
    "\\left\\{\\begin{array}{l} \\mu_k = \\frac{1}{m} \\sum_{i=1}^m z^{(i)}_k \\\\ \\sigma^2_k = \\frac{1}{m} \\sum_{i=1}^m {(z^{(i)}_k - \\mu_k)}^2 \\end{array}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "so **feature $k$ does not make use of any information from feature $p \\neq k$**.\n",
    "\n",
    "Now,\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial z^{(j)}_k} = \\sum_{i=1}^m \\underbrace{\\frac{\\partial J}{\\partial \\tilde z^{(i)}_k}}_{\\text{given}} \\underbrace{\\frac{\\partial \\tilde z^{(i)}_k}{\\partial z^{(i)}_{k, \\text{norm}}}}_{\\gamma_k} \\underbrace{\\frac{\\partial z^{(i)}_{k, \\text{norm}}}{\\partial z^{(j)}_k}}_{\\text{focus here}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial z^{(i)}_{k, \\text{norm}}}{\\partial z^{(j)}_k} = & \\frac{1}{\\sigma^2_k + \\epsilon} \n",
    "\\left\\{\n",
    "\\left(\\mathbb{1}_{\\{i=j\\}} - \\frac{1}{m}\\right)\n",
    "\\sqrt{\\sigma^2_k + \\epsilon} + \n",
    "(z^{(i)}_k -\\mu_k) \\frac{1}{2\\sqrt{\\sigma^2_k + \\epsilon}} \\frac{1}{m} \\sum_{s=1}^m \n",
    "\\left[2(z^{(s)}_k -\\mu_k)\\left(\\mathbb{1}_{\\{s=j\\}} - \\frac{1}{m}\\right)\\right]\n",
    "\\right\\} \\\\\n",
    " = & \\frac{1}{\\sqrt{\\sigma^2_k + \\epsilon}}\\left(\\mathbb{1}_{\\{i=j\\}} - \\frac{1}{m}\\right) + \\frac{1}{{(\\sigma^2_k + \\epsilon)}^{\\frac{3}{2}}}\\frac{1}{m}(z^{(i)}_k -\\mu_k)(z^{(j)}_k -\\mu_k)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J}{\\partial z^{(j)}_k} = & \\sum_{i=1}^m \\frac{\\partial J}{\\partial \\tilde z^{(i)}_k} \\gamma_k \\left\\{ \\frac{1}{\\sqrt{\\sigma^2_k + \\epsilon}}\\left(\\mathbb{1}_{\\{i=j\\}} - \\frac{1}{m}\\right) + \\frac{1}{{(\\sigma^2_k + \\epsilon)}^{\\frac{3}{2}}}\\frac{1}{m}(z^{(i)}_k -\\mu_k)(z^{(j)}_k -\\mu_k)\\right\\} \\\\\n",
    "= & \\underbrace{\\frac{\\gamma_k}{\\sqrt{\\sigma^2_k + \\epsilon}} \\frac{\\partial J}{\\partial \\tilde z^{(j)}_k}}_{\\text{vanila gradient treating $\\mu_k$ and $\\sigma^2_k$ as given}} + \\underbrace{\\frac{\\gamma_k}{m\\sqrt{\\sigma^2_k + \\epsilon}}  \\sum_{i=1}^m \\frac{\\partial J}{\\partial \\tilde z^{(i)}_k} \\left\\{ \\frac{(z^{(i)}_k -\\mu_k)(z^{(j)}_k -\\mu_k)}{\\sigma^2_k + \\epsilon} -1\\right\\}}_{\\text{additional feedback through $\\mu_k$ and $\\sigma^2_k$}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5dec35-b623-42f5-b924-60ae0c889da0",
   "metadata": {},
   "source": [
    "#### Implementing the Backprop for Batch Norm (vectorized version)\n",
    "Re-write the above equation as:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J}{\\partial z^{(j)}_k} = & \\frac{\\gamma_k}{\\sqrt{\\sigma^2_k + \\epsilon}} \\frac{\\partial J}{\\partial \\tilde z^{(j)}_k} + \\frac{\\gamma_k(z^{(j)}_k -\\mu_k)}{m(\\sigma^2_k + \\epsilon)}  \\sum_{i=1}^m \\frac{\\partial J}{\\partial \\tilde z^{(i)}_k} \\frac{(z^{(i)}_k -\\mu_k)}{\\sqrt{\\sigma^2_k + \\epsilon}}  - \\frac{\\gamma_k}{m\\sqrt{\\sigma^2_k + \\epsilon}}  \\sum_{i=1}^m \\frac{\\partial J}{\\partial \\tilde z^{(i)}_k} \\\\\n",
    "\\left[\\frac{\\partial J}{\\partial z}\\right]_{jk} = & \\frac{\\gamma_k}{\\sqrt{\\sigma^2_k + \\epsilon}} \\left[\\frac{\\partial J}{\\partial \\tilde z}\\right]_{jk} + \\frac{\\gamma_k}{\\sqrt{\\sigma^2_k + \\epsilon}} \\left[Z_{\\text{norm}}\\right]_{jk} \\cdot \\frac{1}{m} \\mathsf{np.sum} \\left(\\left[\\frac{\\partial J}{\\partial \\tilde z}\\right]_{\\cdot k} * \\left[Z_{\\text{norm}}\\right]_{\\cdot k} \\right) - \\frac{\\gamma_k}{\\sqrt{\\sigma^2_k + \\epsilon}} \\cdot \\frac{1}{m} \\mathsf{np.sum} \\left(\\left[\\frac{\\partial J}{\\partial \\tilde z}\\right]_{\\cdot k} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "$$\n",
    "dZ = \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} d\\tilde Z + \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} Z_{\\text{norm}} \\cdot \\frac{1}{m} \\mathsf{np.sum}\\left(d\\tilde Z * Z_{\\text{norm}}, \\mathsf{axis = 1} \\right) - \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}}  \\cdot \\frac{1}{m} \\mathsf{np.sum}\\left(d\\tilde Z, \\mathsf{axis = 1} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d368bf1-7782-4c3d-962b-9718f7d67836",
   "metadata": {},
   "source": [
    "#### Why does Batch Norm work?\n",
    "1. Similar to normalizing the input features (which makes the cost space less skewed and speeds up gradient descent), Batch Norm normalises values in the hidden units (which are inputs to the next layer).\n",
    "2. Bath Norm makes the weights of later layers more robust to changes to weights in earlier layers.\n",
    "\n",
    "#### Regularization effect of Batch Norm\n",
    "Batch normalization has a slight regularization effect. This is because:\n",
    "1. During the training time, we **compute the means and variances for each layer using only a single mini-batch at a time**, which  introduces noise to the statistics.\n",
    "2. Recall that the regularization effect of dropout comes from the **introduction of** multiplicative **noise** (in the form of $\\times \\; 0$ or $\\times \\; 1$). The regularization effect of Batch Norm comes from the introduction of both additive noise (from the mean) and multiplicative noise (from the variance).\n",
    "3. The smaller the variation of means and variances (across the mini-batches), the smaller the noise, and thus the smaller the regularization effect. Therefore, **a larger mini-batch size, say 512 instead of 256, has a smaller regularization effect**.\n",
    "\n",
    "#### Batch Norm at test time\n",
    "Need measures of $\\mu$ and $\\sigma^2$ for each layer to be used at training time. This is usually done by keeping **running averages** (expoentially weighted running averages) of $\\mu$ and $\\sigma^2$ at the training time. Note that the default approach is to estimate these averages but *not* use them in the training time. If one uses the running averages during the training time, the additional (backprop) feedback through $\\mu$ and $\\sigma^2$ would be smaller and thus the regularization effect. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datascience)",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
