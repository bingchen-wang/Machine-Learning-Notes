{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "## Gensim Implementation\n",
        "\n",
        "Author: Bingchen Wang\n",
        "\n",
        "Last updated: 10 Jan, 2023"
      ],
      "metadata": {
        "id": "lm5slOMh1pb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HHJp6UyRupGr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Pre-trained Word2vec Google News Model\n",
        "\n",
        "Here we use the <a href = \"https://github.com/RaRe-Technologies/gensim-data\">Gensim API</a> to import the model. A helpful Word2Vec Demo can be found <a href= 'https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py'>here</a>."
      ],
      "metadata": {
        "id": "T5o9HbnVzReO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wv = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "suWLcJIYusVu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the dimension of the word embedding:"
      ],
      "metadata": {
        "id": "VJSvIf0J3GTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dimensionality of a word vector: {wv['king'].shape}.\")\n",
        "print(f\"Norm of the word vector for 'king': {np.linalg.norm(wv['king'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw6rZ_WYzx8X",
        "outputId": "8fab5995-0a59-4ee8-b9d5-65ee3f2ca7bf"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensionality of a word vector: (300,).\n",
            "Norm of the word vector for 'king': 2.90225887298584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_sFErqrH6d1",
        "outputId": "cd2c1e07-fd0a-49b8-f4bd-637d76c1eb26"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the cosine similarity between two words\n",
        "\n",
        "$$\n",
        "\\cos(\\vec u, \\vec v) = \\frac{\\vec u \\cdot \\vec v}{\\Vert \\vec u \\Vert_2 \\Vert \\vec v \\Vert_2}\n",
        "$$"
      ],
      "metadata": {
        "id": "BIgdbjOA3rWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(u,v):\n",
        "  # Special case. u = [0, 0] and v = [0 ,0]\n",
        "  if np.all(u == v):\n",
        "    return 1\n",
        "  # Calculate the components needed for the cosine similarity\n",
        "  norm_u = np.linalg.norm(u, ord = 2)\n",
        "  norm_v = np.linalg.norm(v, ord = 2)\n",
        "  dot_product = np.dot(u,v)\n",
        "  # Avoid the division by 0 issue\n",
        "  if np.isclose(norm_u * norm_v, 0, atol = 1e-32):\n",
        "    return 0\n",
        "  \n",
        "  cosine_similarity = dot_product/(norm_u*norm_v)\n",
        "  \n",
        "  return cosine_similarity\n",
        "  "
      ],
      "metadata": {
        "id": "EZXsQ_oM2RS8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare our self-defined function with the function provided by gensim\n",
        "print(cosine_similarity(wv['king'], wv['queen']), wv.similarity('king','queen'))\n",
        "\n",
        "# We can also use our function to check the similarity between differences\n",
        "print(cosine_similarity(wv['king']- wv['queen'], wv['male'] - wv['female']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8cas6vJ5cct",
        "outputId": "cfa12d83-c07c-4824-b2e3-5338aeaf9de4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6510956 0.6510957\n",
            "0.27453682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analogical Reasoning\n",
        "\n",
        "Here we design a function that performs analogical reasoning. But note that the gensim library has default functions to do that."
      ],
      "metadata": {
        "id": "wYrZS2KF7W4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(gensim.__version__)\n",
        "for index, word in enumerate(wv.index2word): #note that this attribute is replaced by index_to_key in the latest version of gen\n",
        "    if index == 10:\n",
        "        break\n",
        "    print(f\"word #{index}/{len(wv.index2word)} is {word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK3jvXm_569h",
        "outputId": "bb69c7c2-cc13-43ec-90e5-8e4e0e43bc0c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6.0\n",
            "word #0/3000000 is </s>\n",
            "word #1/3000000 is in\n",
            "word #2/3000000 is for\n",
            "word #3/3000000 is that\n",
            "word #4/3000000 is is\n",
            "word #5/3000000 is on\n",
            "word #6/3000000 is ##\n",
            "word #7/3000000 is The\n",
            "word #8/3000000 is with\n",
            "word #9/3000000 is said\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_analogy(w_a,w_b,w_c,word2vec_map):\n",
        "  e_a, e_b, e_c = word2vec_map[w_a], word2vec_map[w_b], word2vec_map[w_c]\n",
        "  words = word2vec_map.index2word\n",
        "  cos_sim = [cosine_similarity(e_a - e_b, e_c - word2vec_map[w]) for w in words[:100000]] #due to computation time, we limit the scope to the first 100k words\n",
        "  max_index = np.argmax(cos_sim)\n",
        "  best_word =  words[max_index]\n",
        "  return best_word"
      ],
      "metadata": {
        "id": "5VFMlZTM6Ys8"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_analogy('man','boy','woman', wv))\n",
        "print(complete_analogy('man','king','woman', wv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuZR_7n79U-y",
        "outputId": "41dd6ae3-dfa5-488d-f06a-c9e66a31fa24"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "girl\n",
            "king\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argwhere(np.array(wv.index2word) == 'queen')\n",
        "\n",
        "print(cosine_similarity(wv['man'] - wv['king'], wv['woman']- wv['queen']))\n",
        "print(cosine_similarity(wv['man'] - wv['king'], wv['woman']- wv['king']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMW7B7QqCH2R",
        "outputId": "93eb86fb-b254-4e22-f626-5734c16c1b9b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7580351\n",
            "0.8824964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar(positive = ['woman', 'king'], negative = ['man'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVwf8f4DAqGq",
        "outputId": "1f11b442-21b7-485e-f20c-0fee3fac79e3"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118192911148071),\n",
              " ('monarch', 0.6189674139022827),\n",
              " ('princess', 0.5902431011199951),\n",
              " ('crown_prince', 0.5499460697174072),\n",
              " ('prince', 0.5377321243286133),\n",
              " ('kings', 0.5236844420433044),\n",
              " ('Queen_Consort', 0.5235945582389832),\n",
              " ('queens', 0.518113374710083),\n",
              " ('sultan', 0.5098593235015869),\n",
              " ('monarchy', 0.5087411999702454)]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar(positive = ['woman', 'footballer'], negative = ['man'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjx6aRv2F0ht",
        "outputId": "54a9e863-7cbb-4371-c01a-86274665b65b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('footballers', 0.6041663885116577),\n",
              " ('sportswoman', 0.5877651572227478),\n",
              " ('actress', 0.5462757349014282),\n",
              " ('cricketer', 0.5384135246276855),\n",
              " ('supermodel', 0.5337250232696533),\n",
              " ('Footballer', 0.5334779620170593),\n",
              " ('popstar', 0.5287024974822998),\n",
              " ('model_Sophie_Anderton', 0.5286864042282104),\n",
              " ('Sarah_Marbeck', 0.5237902998924255),\n",
              " ('starlet', 0.5232126712799072)]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The differences between our `complete_analogy` function and gensim's `most_similar` seem to suggest that the latter exclude certain words (specifically, the words used for the analogy task) from consideration."
      ],
      "metadata": {
        "id": "N2ve5kn4DowF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_analogy_improved(w_a,w_b,w_c,word2vec_map):\n",
        "  e_a, e_b, e_c = word2vec_map[w_a], word2vec_map[w_b], word2vec_map[w_c]\n",
        "  words = word2vec_map.index2word\n",
        "  cos_sim = np.array([[w,cosine_similarity(e_a - e_b, e_c - word2vec_map[w])] for w in words[:100000] if w not in {w_a,w_b,w_c}]) #due to computation time, we limit the scope to the first 100k words\n",
        "  max_index = np.argmax(cos_sim[:,1])\n",
        "  best_word =  cos_sim[max_index,0]\n",
        "\n",
        "  return best_word"
      ],
      "metadata": {
        "id": "Z0qnpEICEVP4"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_analogy_improved('man','king','woman', wv))\n",
        "print(complete_analogy_improved('male','footballer','female', wv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b55W011Erio",
        "outputId": "1305d43a-f53b-427b-8ea2-311278eb68f9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen\n",
            "footballers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the results match. (Note that in `complete_analogy_improved`, we considered only the first 100,000 words in the vocabulary to save on computation.)\n",
        "\n",
        "Interestingly, the analogical reasoning task does not suggest similar gender bias that were evident in <a href = \"https://arxiv.org/abs/1607.06520\">Bolukbasi et al. (2016)</a>. It should be noted that:\n",
        "- Here, we did not normalize the word embeddings.\n",
        "- Perhaps, the word2vec Google News pretrained embedding has been updated since <a href = \"https://arxiv.org/abs/1607.06520\">Bolukbasi et al. (2016)</a>."
      ],
      "metadata": {
        "id": "KiAc9GxZF4n0"
      }
    }
  ]
}